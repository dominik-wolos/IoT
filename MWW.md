# Metody Wnioskowania Wielokryterialnego - SkrÃ³t do zaliczenia

## 1. PODSTAWOWE POJÄ˜CIA

### 1.1 Funkcje celu
- **CharakteryzujÄ… obiekt jako caÅ‚oÅ›Ä‡** (np. ciÄ™Å¼ar, sprawnoÅ›Ä‡, koszt, estetyka)
- WyraÅ¼one w rÃ³Å¼nych jednostkach (zÅ‚, km, punkty)
- MogÄ… byÄ‡ **mierzalne** lub **niemierzalne** (skala punktowa)
- PrzeksztaÅ‚cenie na **kryterium** - okreÅ›lamy czy MAX czy MIN

### 1.2 Zmienne i parametry
- **Zmienne decyzyjne (x)** - podlegajÄ… wariancjom w procesie optymalizacji
- **Parametry** - wielkoÅ›ci ustalone wczeÅ›niej (staÅ‚e)
- **Obszar dopuszczalny X** - wyznaczony przez ograniczenia

### 1.3 Ograniczenia
**Brzegowe:**
- NakÅ‚adane na elementy wektora zmiennych: x_i^min â‰¤ x_i â‰¤ x_i^max

**Zachowawcze (funkcjonalne):**
- ZaleÅ¼noÅ›ci miÄ™dzy zmiennymi i parametrami
- MogÄ… tworzyÄ‡ obszary separowane lub puste

### 1.4 Zadanie optymalizacji
**Jednokryterialne:**
```
ZnaleÅºÄ‡ x* = [xâ‚*, xâ‚‚*, ..., xâ‚˜*]áµ€
optymalizujÄ…ce F(x)
przy ograniczeniach: háµ¢(x) = 0, gâ‚–(x) â‰¤ 0
```

**Wielokryterialne:**
```
ZnaleÅºÄ‡ x* = [xâ‚*, xâ‚‚*, ..., xâ‚˜*]áµ€
optymalizujÄ…ce F(x) = [Fâ‚(x), Fâ‚‚(x), ..., Fâ‚™(x)]áµ€
przy ograniczeniach: háµ¢(x) = 0, gâ‚–(x) â‰¤ 0
```

---

## 2. OPTYMALIZACJA WIELOKRYTERIALNA

### 2.1 Optimum w sensie Pareto (OSP)
**RozwiÄ…zanie x* jest OSP, gdy:**
- WartoÅ›Ä‡ Å¼adnego kryterium nie moÅ¼e byÄ‡ poprawiona bez pogorszenia innego
- Dla kaÅ¼dego jâˆˆJ: Fâ±¼(xâ») â‰¤ Fâ±¼(x*) oraz âˆƒp: Fâ‚š(xâ») > Fâ‚š(x*)

**Synonimy:**
- RozwiÄ…zania niezdominowane, sprawne, efektywne, kompromisowe, Pareto-optymalne

### 2.2 Typy rozwiÄ…zaÅ„
1. **Dopuszczalne** - speÅ‚niajÄ… wszystkie ograniczenia
2. **Niezdominowane** - jednoznacznie okreÅ›lone matematycznie (Front Pareto)
3. **Kompromisowe** - wybrane ze zbioru niezdominowanych (np. minimalizacja dystansu)
4. **Reprezentatywne** - czÄ™sto wystÄ™pujÄ… w podzbiorach kompromisowych
5. **Preferowane** - wyznaczone ze zbioru niezdominowanych (niejednoznaczne)

### 2.3 Relacje porzÄ…dku czÄ™Å›ciowego
**StoÅ¼ek dodatni:** Câ‚€ = {F = [Fâ‚, ..., Fâ‚™]áµ€ : Fáµ¢ â‰¥ 0 (i = 1, ..., n)}

**Relacja:** Fáµƒ <c Fáµ‡, jeÅ¼eli Fáµ‡ âˆˆ CFáµƒ

---

## 3. PUNKTY CHARAKTERYSTYCZNE W PRZESTRZENI KRYTERIALNEJ

### 3.1 Punkty naroÅ¼ne (F^n)
- Wyznaczane przez minimalizacjÄ™ kaÅ¼dego kryterium osobno
- TworzÄ… wektor idealny: F^n_j(x) = F^o_j(x)

### 3.2 Punkt idealny (wektor idealny) F^o
```
F^o(x) = [F^oâ‚(x), F^oâ‚‚(x), ..., F^oâ‚™(x)]áµ€
gdzie F^o_j(x) = min{F^j_i(x)} dla kaÅ¼dego kryterium
```
- **RozwiÄ…zanie zazwyczaj fikcyjne**

### 3.3 Punkt antyidealny F^ai
```
F^ai_j(x) = max{F^i_j(x)} dla wszystkich kryteriÃ³w
```
- Najmniej preferowany poziom wszystkich celÃ³w jednoczeÅ›nie

### 3.4 Punkt nadir F^na
```
F^na_j(x) = max{F^i_j(x)} z rozwiÄ…zaÅ„ niezdominowanych
```
- Jak antyidealny, ale tylko z rozwiÄ…zaÅ„ Pareto

### 3.5 Punkty referencyjne
- ReprezentujÄ… poziom aspiracji/satysfakcji decydenta
- Punkt odniesienia w procedurze porzÄ…dkowania preferencji

### 3.6 Ocena zadowalajÄ…ca
- Punkt w przestrzeni kryterialnej: [fâ‚^S, fâ‚‚^S, ..., fâ±¼^S]
- WierzchoÅ‚ek stoÅ¼ka satysfakcji

---

## 4. PROBLEMATYKI DECYZYJNE

### PÎ± - Problematyka wyboru
```
ZbiÃ³r dopuszczalnych A â†’ PodzbiÃ³r najlepszych A' + Odrzucone A\A'
```

### PÎ² - Problematyka klasyfikacji
```
ZbiÃ³r A â†’ Klasa 1, Klasa 2, ..., Klasa p
```

### PÎ³ - Problematyka porzÄ…dkowania
```
ZbiÃ³r A â†’ Ranking (porzÄ…dek czÄ™Å›ciowy lub caÅ‚kowity)
```

---

## 5. METODY SKALARYZACJI

### 5.1 Rodzaje strategii

**LINIOWE (kompensacyjne):**
1. **WskaÅºnik sumacyjny:**
   - ZwykÅ‚y: Fâº = Î£câ±¼
   - WaÅ¼ony: Fâº = Î£wâ±¼câ±¼

2. **Åšrednia arytmetyczna:**
   - ZwykÅ‚a: Fâº = (1/J)Î£câ±¼
   - WaÅ¼ona: Fâº = (1/J)Î£wâ±¼câ±¼

3. **WaÅ¼ona dÅ‚ugoÅ›Ä‡ wektora:**
   - Fâº = âˆš(Î£wâ±¼câ±¼Â²) lub Fâº = âˆš(Î£wâ±¼Â²câ±¼Â²)

**KONIUNKCYJNE (niekompensacyjne):**
1. **WskaÅºnik multiplikacyjny:**
   - ZwykÅ‚y: Fâº = Î câ±¼
   - WaÅ¼ony: Fâº = Î câ±¼^wâ±¼ lub Fâº = Î (wâ±¼câ±¼)

2. **Geometryczna Å›rednia waÅ¼ona:**
   - Fâº = á´¶âˆš(Î wâ±¼câ±¼)

3. **WskaÅºnik paraboliczny:**
   - Fâº = Î (câ±¼)^Î±â±¼ lub Fâº = Î (wâ±¼câ±¼)^Î±â±¼

**ALTERNATYWNE:**
- Fâº = Î [j/(eâ±¼-Fâ±¼)]^Î±â±¼

### 5.2 Normowanie (kodowanie)

**Cel:** Sprowadzenie wartoÅ›ci do przedziaÅ‚u [0,1] bez jednostek

**Metoda Unitaryzacji Zerowanej (MUZ):**
```
c_ijMUZ = (cáµ¢â±¼ - cáµ¢â±¼min)/(cáµ¢â±¼max - cáµ¢â±¼min)
```

**Inne metody normowania:**
1. **Odchylenie standardowe:**
   - záµ¢â±¼ = (xáµ¢â±¼ - XÌ„â±¼)/S(Xâ±¼)

2. **RozstÄ™p zmiennych:**
   - záµ¢â±¼ = xáµ¢â±¼/(max xáµ¢â±¼ - min xáµ¢â±¼)

3. **Åšrednia arytmetyczna:**
   - záµ¢â±¼ = xáµ¢â±¼/XÌ„â±¼

4. **Suma realizacji:**
   - záµ¢â±¼ = xáµ¢â±¼/Î£xáµ¢â±¼

5. **DÅ‚ugoÅ›Ä‡ wektora:**
   - záµ¢â±¼ = xáµ¢â±¼/âˆš[Î£xáµ¢â±¼Â²]^(1/2)

### 5.3 Kodowanie

**Normowanie wzglÄ™dem wartoÅ›ci ekstremalnej:**
- Stymulanty: z'áµ¢â±¼ = xáµ¢â±¼/xâ±¼max
- Destymulanty: x'áµ¢â±¼ = 1/xáµ¢â±¼, potem z'áµ¢â±¼ = x'áµ¢â±¼/x'â±¼max

**Kodowanie Neumana-Morgensterna:**
- Stymulanty: záµ¢â±¼ = (xáµ¢â±¼ - xâ±¼min)/(xâ±¼max - xâ±¼min)
- Destymulanty: záµ¢â±¼ = (xâ±¼max - xáµ¢â±¼)/(xâ±¼max - xâ±¼min)

**Kodowanie Pattern:**
- Stymulanty: záµ¢â±¼ = xáµ¢â±¼/Î£xáµ¢â±¼
- Destymulanty: x'áµ¢â±¼ = 1/xáµ¢â±¼, potem záµ¢â±¼ = x'áµ¢â±¼/Î£x'áµ¢â±¼

### 5.4 Transformacja typÃ³w zmiennych

**Destymulanta â†’ Stymulanta:**
- Dane standaryzowane: destymulanta Ã— (-1)
- Dane zunitaryzowane: 1 - destymulanta

**Nominanta â†’ Stymulanta:**
```
záµ¢â±¼ = {
  1                    dla xáµ¢â±¼ = Nâ±¼
  -1                   dla xáµ¢â±¼ < Nâ±¼
  (xáµ¢â±¼ - Nâ±¼ - 1)/(xáµ¢â±¼ - Nâ±¼ + 1)  dla xáµ¢â±¼ > Nâ±¼
}
```

---

## 6. METODY Z RELACJÄ„ PRZEWYÅ»SZANIA

### 6.1 Podstawy teoretyczne (Roy)

**Nowe sytuacje preferencyjne:**
- **I** - preferencja rÃ³wnowaÅ¼noÅ›ci (symetryczna, zwrotna)
- **Q** - preferencja sÅ‚aba (asymetryczna, przeciwzwrotna)
- **P** - preferencja silna (asymetryczna, przeciwzwrotna)
- **R** - nieporÃ³wnywalnoÅ›Ä‡ (symetryczna, przeciwzwrotna)

**Relacje zgrupowane:**
- **N** - brak preferencji (brak P i Q, brak rozrÃ³Å¼nienia I i R)
- **J** - przypuszczenie preferencji (aâ‚–Qaâ‚— lub aâ‚–Iaâ‚—)
- **L** - preferencja w szerokim sensie (aâ‚–Paâ‚— lub aâ‚–Qaâ‚—)
- **K** - preferencja (aâ‚–Paâ‚— lub aâ‚–Raâ‚—)
- **S** - przewyÅ¼szanie (aâ‚–Paâ‚— lub aâ‚–Qaâ‚— lub aâ‚–Iaâ‚—)

### 6.2 Progi

**PrÃ³g rÃ³wnowaÅ¼noÅ›ci qáµ¢[fáµ¢(aâ‚–)]:**
```
0 â‰¤ fáµ¢(aâ‚–) - fáµ¢(aâ‚—) â‰¤ qáµ¢[fáµ¢(aâ‚–)] âŸ¹ aâ‚– Iáµ¢ aâ‚—
fáµ¢(aâ‚–) - fáµ¢(aâ‚—) > qáµ¢[fáµ¢(aâ‚—)] âˆ§ fáµ¢(aâ‚–) â‰¥ fáµ¢(aâ‚—) âŸ¹ aâ‚– Láµ¢ aâ‚—
```

**PrÃ³g preferencji páµ¢[fáµ¢(aâ‚–)]:**
```
fáµ¢(aâ‚–) - fáµ¢(aâ‚—) > páµ¢[fáµ¢(aâ‚–)] âŸ¹ aâ‚– Páµ¢ aâ‚—
0 â‰¤ fáµ¢(aâ‚–) - fáµ¢(aâ‚—) â‰¤ páµ¢[fáµ¢(aâ‚—)] âŸ¹ aâ‚– Jáµ¢ aâ‚—
```

**PrÃ³g weta váµ¢[fáµ¢(aâ‚—)]:**
- Odrzuca preferencjÄ™ nawet przy silnej preferencji dla wszystkich innych kryteriÃ³w

**PowiÄ…zanie:**
```
f(aâ‚–) > f(aâ‚—) âŸ¹
  - aâ‚– Iáµ¢ aâ‚—  gdy fáµ¢(aâ‚–) - fáµ¢(aâ‚—) â‰¤ qáµ¢[fáµ¢(aâ‚—)]
  - aâ‚– Qáµ¢ aâ‚—  gdy qáµ¢[fáµ¢(aâ‚—)] < fáµ¢(aâ‚–) - fáµ¢(aâ‚—) â‰¤ páµ¢[fáµ¢(aâ‚–)]
  - aâ‚– Páµ¢ aâ‚—  gdy fáµ¢(aâ‚–) - fáµ¢(aâ‚—) > páµ¢[fáµ¢(aâ‚—)]
```

### 6.3 Metody ELECTRE

**ELECTRE I - Wyznaczenie jÄ…dra:**
- Elementy jÄ…dra nie przewyÅ¼szajÄ… siÄ™ wzajemnie
- KaÅ¼dy element spoza jÄ…dra jest przewyÅ¼szany przez co najmniej jeden element jÄ…dra

**ELECTRE II - Dwa preporzÄ…dki:**
- Etap I: PodziaÅ‚ kryteriÃ³w na 3 klasy (Fâ‚ przewyÅ¼sza Fâ‚‚, odwrotnie, rÃ³wnowaÅ¼ne)
- Etap II: Zliczanie wag w kaÅ¼dej klasie (skalaryzacja wewnÄ™trzna)

**ELECTRE III - WartoÅ›ciowa relacja przewyÅ¼szania:**
- Etap I: Indeks zgodnoÅ›ci dla kaÅ¼dej pary
- Etap II: WskaÅºnik niezgodnoÅ›ci dla kaÅ¼dej pary
- Etap III: StopieÅ„ przewyÅ¼szania S(Fâ‚,Fâ‚‚)
- Etap IV: PreporzÄ…dek zstÄ™pujÄ…cy i wstÄ™pujÄ…cy
- Etap V: Ranking koÅ„cowy (moÅ¼liwe rozwiÄ…zania nieporÃ³wnywalne)

**ELECTRE IV - Bez wag kryteriÃ³w:**
- Mocna i sÅ‚aba preferencja
- Mocna i sÅ‚aba relacja przewyÅ¼szania
- PreporzÄ…dek jak w ELECTRE III

### 6.4 PROMETHEE (Brans, Mareschal)

**Podstawy:**
- PorÃ³wnanie parami wariantÃ³w
- RÃ³Å¼nice dáµ¢(aâ‚–, aâ‚—) = fáµ¢(aâ‚–) - fáµ¢(aâ‚—)
- Im wiÄ™ksza rÃ³Å¼nica, tym silniejsza preferencja

**Funkcja preferencji:**
```
Gáµ¢(aâ‚–, aâ‚—) = Fáµ¢[dáµ¢(aâ‚–, aâ‚—)]
WÅ‚aÅ›ciwoÅ›Ä‡: Gáµ¢(aâ‚–, aâ‚—) > 0 âŸ¹ Gáµ¢(aâ‚—, aâ‚–) = 0
```

**6 typÃ³w uogÃ³lnionych kryteriÃ³w** (funkcje preferencji)

### 6.5 EXPROM (modyfikacja - Diakoulaki, Koumoutsos)

**Krok 1:** Zagregowany sÅ‚aby indeks preferencji
```
WP(aáµ, aË¡) = Ï€(aáµ, aË¡) = Î£â¿áµ¢â‚Œâ‚ wáµ¢Gáµ¢(aáµ, aË¡)
```

**Krok 2:** Zagregowany Å›cisÅ‚y indeks preferencji
```
SP(aáµ, aË¡) = Î£â¿áµ¢â‚Œâ‚ wáµ¢SPáµ¢(aáµ, aË¡)
```

**Krok 3:** CaÅ‚kowity indeks preferencji
```
TP(aáµ, aË¡) = min{1; WP(aáµ, aË¡) + SP(aáµ, aË¡)}
```

**Krok 4:** Dodatni i ujemny przepÅ‚yw przewyÅ¼szania
```
Ï†âº(aáµ) = 1/(m-1) Î£áµâ‚—â‚Œâ‚ TP(aáµ, aË¡)
Ï†â»(aáµ) = 1/(m-1) Î£áµâ‚—â‚Œâ‚ TP(aË¡, aáµ)
```

**Krok 5:** PrzepÅ‚yw netto
```
Ï†(aáµ) = Ï†âº(aáµ) - Ï†â»(aáµ)
```

### 6.6 MAPPAC (Matarazzo)

- Macierz preferencji i rÃ³wnowaÅ¼noÅ›ci
- Progi preferencji dla kaÅ¼dego kryterium
- Bazowe wskaÅºniki preferencji dla par rozwiÄ…zaÅ„ i kryteriÃ³w
- Zagregowana macierz preferencji
- Indeks koÅ„cowy dla kaÅ¼dego rozwiÄ…zania
- Ranking (najwiÄ™kszy indeks = pierwsze miejsce)

### 6.7 ORESTE (Roubens)

- PreporzÄ…dek zupeÅ‚ny dla kryteriÃ³w
- Progi preferencji, rÃ³wnowaÅ¼noÅ›ci, nieporÃ³wnywalnoÅ›ci
- Test rÃ³wnowaÅ¼noÅ›ci i nieporÃ³wnywalnoÅ›ci
- Zamiana preporzÄ…dku na rangi
- Macierz intensywnoÅ›ci preferencji
- Ranking koÅ„cowy

---

## 7. METODA ANALIZY GRUPOWEJ - BLIN

**Cel:** Agregacja uporzÄ…dkowaÅ„ preferencyjnych grupy decydentÃ³w

**Dane:**
- A = {aâ‚, ..., aâ‚˜} - zbiÃ³r decyzji
- B = {bâ‚, ..., bâ‚™} - zbiÃ³r decydentÃ³w
- Oâ‚– âŠ‚ A Ã— A - uporzÄ…dkowanie k-tego decydenta

**Procedura:**
1. **Macierz preferencji Sâ‚–** dla kaÅ¼dego decydenta (wartoÅ›ci 0 lub 1)
2. **Macierz sumaryczna:** N = Î£â‚–â‚Œâ‚â¿ Sâ‚–
3. **Preferencja spoÅ‚eczna (rozmyta):** Î¼á´¿(aáµ¢, aâ±¼) = náµ¢â±¼/n
4. **Î±-obciÄ™cie:** Râ‚œ = {(aáµ¢, aâ±¼): Î¼á´¿(aáµ¢, aâ±¼) â‰¥ t}

**PrzykÅ‚ad:**
- JeÅ›li wszyscy decydenci: a > b âŸ¹ Î¼á´¿(a, b) = 1
- JeÅ›li 70% decydentÃ³w: a > b âŸ¹ Î¼á´¿(a, b) = 0,7

---

## 8. METODA AHP (Analytic Hierarchy Process - Saaty)

### 8.1 Charakterystyka
- UwzglÄ™dnia wpÅ‚yw psychiki czÅ‚owieka
- Bazuje na obliczeniach matematycznych
- Hierarchiczna struktura problemu
- PorÃ³wnania parami

### 8.2 Skala ocen Saaty'ego

| Nota | Opis | Dominacja |
|------|------|-----------|
| 1 | RÃ³wnowaÅ¼noÅ›Ä‡ | brak |
| 3 | SÅ‚aba przewaga | sÅ‚aba |
| 5 | Umiarkowana przewaga | umiarkowana |
| 7 | Silna przewaga | silna |
| 9 | Absolutna przewaga | absolutna |
| 2,4,6,8 | WartoÅ›ci poÅ›rednie | - |

### 8.3 Procedura (4 fazy)

**Faza 1: Hierarchiczna struktura**
- Cel nadrzÄ™dny
- Kryteria i podkryteria
- Warianty decyzyjne

**Faza 2: OkreÅ›lenie preferencji**
- PorÃ³wnanie parami kryteriÃ³w (macierz)
- PorÃ³wnanie parami wariantÃ³w dla kaÅ¼dego kryterium
- Skala {1/9, 1/8, ..., 1/2, 1, 2, ..., 8, 9}

**Faza 3: Normalizacja i wektory wÅ‚asne**
- Normalizacja macierzy porÃ³wnaÅ„
- Obliczenie wektorÃ³w skali (Å›rednie arytmetyczne kolumn)
- Badanie globalnej spÃ³jnoÅ›ci (CR < 0,10)

**Faza 4: Obliczenie uÅ¼ytecznoÅ›ci**
```
Ocena wariantu = Î£(ocena w kryterium Ã— waga kryterium)
```

**PrzykÅ‚ad obliczeniowy:**
- Normalizacja: suma kolumny â†’ dzielenie kaÅ¼dego elementu
- Wektor skali: Å›rednia arytmetyczna wierszy znormalizowanej macierzy
- Ocena koÅ„cowa: iloczyn skalarny wektorÃ³w ocen i wag

---

## 9. METODY LEKSYKOGRAFICZNE I HIERARCHICZNE

### 9.1 Metoda leksykograficzna

**ZaÅ‚oÅ¼enia:**
- Hierarchia kryteriÃ³w (uporzÄ…dkowanie waÅ¼noÅ›ci)
- WartoÅ›ci liczbowe kryteriÃ³w
- Brak kompensacji miÄ™dzy kryteriami

**Procedura:**
1. UporzÄ…dkowanie kryteriÃ³w wg waÅ¼noÅ›ci: Fâ‚„ > Fâ‚‚ > Fâ‚… > Fâ‚ > Fâ‚ƒ
2. Optymalizacja wg najwaÅ¼niejszego kryterium (Fâ‚„)
3. WybÃ³r rozwiÄ…zaÅ„ o wartoÅ›ciach MAX/MIN
4. JeÅ›li jedno rozwiÄ…zanie â†’ KONIEC
5. JeÅ›li wiele â†’ optymalizacja wg kolejnego kryterium (Fâ‚‚)
6. Powtarzanie aÅ¼ do jednego rozwiÄ…zania lub wyczerpania kryteriÃ³w

**Uwaga:** Zmiana hierarchii kryteriÃ³w zmienia wynik!

### 9.2 Metoda optymalizacji hierarchicznej

**Modyfikacja:** Wprowadzenie dopuszczalnych odchyleÅ„ Îµ

**Ograniczenie dodatkowe:**
```
fáµ¢â‚‹â‚(X) â‰¤ (1 Â± Îµáµ¢â‚‹â‚) Â· fáµ¢â‚‹â‚(xáµ¢â‚‹â‚)
```

- Îµ = 0 â†’ metoda leksykograficzna
- Îµ > 0 â†’ metoda mniej restrykcyjna
- Procedura identyczna jak w metodzie leksykograficznej

### 9.3 Zmodyfikowana metoda leksykograficzna

**Cel:** Wyznaczenie rankingu (nie tylko jednego rozwiÄ…zania)

**Procedura:**
1. Ustalenie hierarchii kryteriÃ³w
2. Wyznaczenie pierwszego rozwiÄ…zania optymalnego (1. miejsce)
3. UsuniÄ™cie tego rozwiÄ…zania ze zbioru
4. Wyznaczenie kolejnego rozwiÄ…zania (2. miejsce)
5. Powtarzanie aÅ¼ do wyczerpania wariantÃ³w

---

## 10. INNE METODY

### 10.1 Metoda ograniczonych kryteriÃ³w (Trade-Off)

**Idea:**
- Ustalenie poziomÃ³w Îµáµ¢ dla kryteriÃ³w
- Optymalizacja wzglÄ™dem wybranego kryterium fáµ¢
- PozostaÅ‚e kryteria jako ograniczenia: fâ±¼(X) â‰¥ Îµâ±¼

```
fáµ¢(X) â†’ MIN
fâ±¼(X) â‰¥ Îµâ±¼ (i = 1,...,M; i â‰  r)
gâ‚–(X) â‰¤ 0 (k = 1,...,K)
hâ±¼(X) = 0 (j = 1,...,J)
```

### 10.2 Metoda kryterium globalnego (Global Criterion)

**Funkcja celu:**
```
[Î£|fáµ¢(X*) - fáµ¢(X)|á´¾ / fáµ¢(X*)]^(1/P) â†’ MIN
```

- P âˆˆ (1, 2) - najczÄ™Å›ciej
- Poszukujemy rozwiÄ…zania bliskiego f(X*)

### 10.3 Metoda funkcji odlegÅ‚oÅ›ci (Distance Function)

**Minimalizacja:**
```
Î£[(fáµ¢(X*) - fáµ¢(X)) / fáµ¢(X*)]á´¾ â†’ MIN
```

**Dla P â†’ âˆ (Metoda Min-Max):**
```
MAX[wáµ¢ Â· (fáµ¢(X*) - fáµ¢(X)) / fáµ¢(X*)] â†’ MIN
```

### 10.4 Metoda Mini-Maxu

**Minimalizacja:**
```
[MAX|(fáµ¢(X*) - fáµ¢(X)) / fáµ¢(X*)|]á´¾ â†’ MIN
```

- Dla P = 2 â†’ minimalizacja odlegÅ‚oÅ›ci miÄ™dzy rozwiÄ…zaniem przybliÅ¼onym a optymalnym

### 10.5 Metoda TOPSIS (Hwang, Masuda)

**Idea:**
- NajbliÅ¼ej punktu idealnego y^id
- Najdalej od punktu antyidealnego y^ai
- Normalizacja wektorowa (zamiast liniowej)

**WskaÅºnik:**
```
fáµ¢(yâ‚™á´°) = MIN[dáµ¢ / (dáµ¢áµ¢ + dâ‚áµ¢)]
```

gdzie:
- dáµ¢áµ¢ = |yâ‚™á´° - y^id| - odlegÅ‚oÅ›Ä‡ od idealnego
- dâ‚áµ¢ = |yâ‚™á´° - y^ai| - odlegÅ‚oÅ›Ä‡ od antyidealnego

### 10.6 Metoda funkcji uÅ¼ytecznoÅ›ci

**Globalna funkcja uÅ¼ytecznoÅ›ci (postaÄ‡ addytywna):**
```
U(x) = Î£áµáµ¢â‚Œâ‚ uáµ¢(gáµ¢(x))
```

gdzie:
- m - liczba kryteriÃ³w
- gáµ¢(x) - wartoÅ›Ä‡ wariantu x na i-tym kryterium
- uáµ¢(gáµ¢(x)) - funkcja uÅ¼ytecznoÅ›ci czÄ…stkowej

**WÅ‚aÅ›ciwoÅ›ci:**
- Agregacja wszystkich kryteriÃ³w do jednej wartoÅ›ci
- Wariant o lepszej uÅ¼ytecznoÅ›ci jest preferowany (xPy)
- NierozrÃ³Å¼nialne dla tej samej wartoÅ›ci (xIy)
- **UÅ¼ytecznoÅ›Ä‡ NIE jest sumÄ… wartoÅ›ci kryteriÃ³w!**

**Dopasowanie:**
- DobÃ³r wspÃ³Å‚czynnikÃ³w liniowych funkcji
- Odtworzenie rankingu wybranego przez decydenta
- WspÃ³Å‚czynnik Kendalla (zgodnoÅ›Ä‡): [-1, 1]
  - 1 = peÅ‚na zgodnoÅ›Ä‡
  - -1 = brak zgodnoÅ›ci

---

## 11. PODSUMOWANIE METOD

### PodziaÅ‚ ze wzglÄ™du na podejÅ›cie:

**1. Metody syntezy do pojedynczego kryterium (skalaryzacja):**
- Normowanie, kodowanie
- Strategia liniowa, koniunkcyjna, alternatywna
- Metoda AHP
- Metoda funkcji uÅ¼ytecznoÅ›ci

**2. Metody z relacjÄ… przewyÅ¼szania:**
- ELECTRE I, II, III, IV
- PROMETHEE, EXPROM
- MAPPAC, ORESTE

**3. Metody leksykograficzne i hierarchiczne:**
- Metoda leksykograficzna (klasyczna i zmodyfikowana)
- Metoda optymalizacji hierarchicznej

**4. Metody interaktywne:**
- Metoda ograniczonych kryteriÃ³w
- Metoda kryterium globalnego
- Metoda funkcji odlegÅ‚oÅ›ci, Mini-Max, TOPSIS

---

## 12. NAJWAÅ»NIEJSZE WZORY DO ZAPAMIÄ˜TANIA

### Normalizacja MUZ:
```
c_ijMUZ = (cáµ¢â±¼ - cáµ¢â±¼min) / (cáµ¢â±¼max - cáµ¢â±¼min)
```

### Kodowanie N-M (stymulanty):
```
záµ¢â±¼ = (xáµ¢â±¼ - xâ±¼min) / (xâ±¼max - xâ±¼min)
```

### WskaÅºnik waÅ¼ony sumacyjny:
```
Fâº = Î£wâ±¼câ±¼  (gdzie Î£wâ±¼ = 1)
```

### Punkt idealny:
```
F^o_j(x) = min{F^j_i(x)} dla kaÅ¼dego j
```

### Optimum Pareto:
```
x* jest OSP âŸº âˆ„xâ»: Fâ±¼(xâ») â‰¤ Fâ±¼(x*) âˆ€j âˆ§ âˆƒp: Fâ‚š(xâ») > Fâ‚š(x*)
```

### AHP - ocena wariantu:
```
Ocena = Î£â¿â±¼â‚Œâ‚ (ocena_wariantu_w_kryterium_j Ã— waga_kryterium_j)
```

---

## 13. WSKAZÃ“WKI DO EGZAMINU

### Co musisz umieÄ‡:
1. âœ… **RozrÃ³Å¼niÄ‡ typy problemÃ³w** (PÎ±, PÎ², PÎ³)
2. âœ… **WyznaczyÄ‡ Front Pareto** (graficznie i analitycznie)
3. âœ… **ZnormalizowaÄ‡/zakodowaÄ‡ dane** (MUZ, N-M, Pattern)
4. âœ… **ObliczyÄ‡ wskaÅºniki skalaryzacyjne** (sumacyjny, multiplikacyjny)
5. âœ… **ZastosowaÄ‡ metodÄ™ AHP** (porÃ³wnania parami, normalizacja, wagi)
6. âœ… **ZrozumieÄ‡ rÃ³Å¼nicÄ™ miÄ™dzy metodami** (skalaryzacja vs relacje przewyÅ¼szania)
7. âœ… **TransformowaÄ‡ typy zmiennych** (destymulantaâ†’stymulanta)
8. âœ… **ZnaÄ‡ punkty charakterystyczne** (idealny, nadir, antyidealny)
9. âœ… **RozumieÄ‡ progi w metodach przewyÅ¼szania** (q, p, v)
10. âœ… **ZastosowaÄ‡ metodÄ™ leksykograficznÄ…** (uporzÄ…dkowanie kryteriÃ³w)

### Typowe pytania:
- Czym rÃ³Å¼ni siÄ™ rozwiÄ…zanie dopuszczalne od niezdominowanego?
- Co to jest optimum w sensie Pareto?
- Jakie sÄ… gÅ‚Ã³wne rodzaje strategii skalaryzacji?
- WymieÅ„ metody normowania i ich zastosowanie
- Opisz metodÄ™ AHP krok po kroku
- Czym rÃ³Å¼niÄ… siÄ™ metody ELECTRE od PROMETHEE?
- Co to jest punkt idealny i nadir?
- Kiedy stosujemy metodÄ™ leksykograficznÄ…?
- Jakie sÄ… wady i zalety skalaryzacji?
- Czym charakteryzujÄ… siÄ™ metody z relacjÄ… przewyÅ¼szania?

### Mnemotechnika:
- **PINAR** - Punkty: **I**dealny, **N**adir, **A**ntyidealny, **R**eferencyjny, na**R**oÅ¼ne
- **3P** - Problematyki: **P**Î± (wybÃ³r), **P**Î² (klasyfikacja), **P**Î³ (porzÄ…dkowanie)
- **LKA** - Strategie: **L**iniowa, **K**oniunkcyjna, **A**lternatywna
- **QPR** - Progi: **Q** (rÃ³wnowaÅ¼noÅ›ci), **P** (preferencji), **R** (weta - nie myliÄ‡ z relacjÄ…!)

---

**Powodzenia na zaliczeniu!** ğŸ“
